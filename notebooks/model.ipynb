{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = load_model('siamese_network', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = Model.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv.dnn.readNetFromCaffe(\"./deploy.prototxt.txt\", \"./res10_300x300_ssd_iter_140000.caffemodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropped_face(file_path):\n",
    "    image = cv.imread(file_path)\n",
    "    (h, w) = image.shape[:2]\n",
    "    blob = cv.dnn.blobFromImage(cv.resize(image, (300, 300)), 1.0,\n",
    "        (300, 300), (104.0, 177.0, 123.0))\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    i = np.argmax(detections[0, 0, :, 2])\n",
    "    confidence = np.max(detections[0, 0, :, 2])\n",
    "    if confidence > 0.6:\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        face = image[startY:endY,startX:endX,:]\n",
    "\n",
    "    return face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_list(input_path):\n",
    "    names=[]\n",
    "    for filename in os.listdir(input_path):\n",
    "        names.append(filename)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(input_path, output_path):\n",
    "    names = name_list(input_path)\n",
    "    for name in names:\n",
    "        image = cropped_face(os.path.join(input_path, name))\n",
    "        cv.imwrite(os.path.join(output_path, name), image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(file_path):\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image[None, :, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.convert_to_tensor(image)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    image = image[None, :, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 964ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "Saptarshi = new.predict(preprocess_file(\"./dataset/Saptarshi.jpg\"))\n",
    "Shubhradeep = new.predict(preprocess_file(\"./dataset/Shubhradeep.jpg\"))\n",
    "Trijeta = new.predict(preprocess_file(\"./dataset/Trijeta.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who(face):\n",
    "    face = preprocess_image(face)\n",
    "    pred = new.predict(face, verbose=0)\n",
    "    distance = []\n",
    "    distance.append(np.sum(np.square(pred-Saptarshi), axis=-1))\n",
    "    distance.append(np.sum(np.square(pred-Shubhradeep), axis=-1))\n",
    "    distance.append(np.sum(np.square(pred-Trijeta), axis=-1))\n",
    "    name = [\"Saptarshi\", \"Shubhradeep\", \"Trijeta\", \"Unknown\"]\n",
    "    if np.min(distance) > 1.8:\n",
    "        return name[3]\n",
    "    return name[np.argmin(distance)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n",
      "Too close to cam\n"
     ]
    }
   ],
   "source": [
    "# ACCESSING VIDEO AND PREDICTING\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "while True:\n",
    "\tret, image = cap.read()\n",
    "\tif ret:\n",
    "\t\t(h, w) = image.shape[:2]\n",
    "\t\tblob = cv.dnn.blobFromImage(cv.resize(image, (300, 300)), 1.0,\n",
    "\t\t\t(300, 300), (104.0, 177.0, 123.0))\n",
    "\t\tnet.setInput(blob)\n",
    "\t\tdetections = net.forward()\n",
    "\t\t# loop over the detections\n",
    "\t\ti = np.argmax(detections[0, 0, :, 2])\n",
    "\t\t# extract the confidence (i.e., probability) associated with the\n",
    "\t\t# prediction\n",
    "\t\tconfidence = np.max(detections[0, 0, :, 2])\n",
    "\t\t# filter out weak detections by ensuring the `confidence` is\n",
    "\t\t# greater than the minimum confidence\n",
    "\t\tif confidence > 0.9:\n",
    "\t\t\t# compute the (x, y)-coordinates of the bounding box for the\n",
    "\t\t\t# object\n",
    "\t\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\t\t\tface = image[startY:endY,startX:endX,:]\n",
    "\t\t\ttry:\n",
    "\t\t\t\tprediction = who(face)\n",
    "\t\t\t\ttext = prediction\n",
    "\t\t\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "\t\t\t\tcv.rectangle(image, (startX, startY), (endX, endY),\n",
    "\t\t\t\t\t\t\t\t(0, 0, 255), 2)\n",
    "\t\t\t\tcv.putText(image, text, (startX, y),\n",
    "\t\t\t\t\t\t\tcv.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(\"Too close to cam\")\n",
    "\t\tif cv.waitKey(1) == ord('q'):\n",
    "\t\t\tbreak\n",
    "\t\t# show the output image\n",
    "\t\tcv.imshow(\"Output\", image)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
